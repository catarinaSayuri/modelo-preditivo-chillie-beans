{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1b3274",
   "metadata": {},
   "source": [
    "## Modelo Supervisionado \n",
    "\n",
    "**Projeto**: Expansão por grupos — classificador de “Bom Desempenho” por região×grupo\n",
    "**Objetivo**: Treinar e avaliar um RandomForest com pipeline (pré-processamento + OHE), escolher limiar ótimo por F1, salvar o modelo e ranquear candidatos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c024851",
   "metadata": {},
   "source": [
    "### Configuração inicial, importações e parâmetros globais\n",
    "\n",
    "- Importa bibliotecas essenciais para:\n",
    "  - Manipulação e análise de dados (`pandas`, `numpy`)\n",
    "  - Visualização (`matplotlib`)\n",
    "  - Modelagem supervisionada (`scikit-learn`)\n",
    "  - Persistência de modelos (`joblib`)\n",
    "\n",
    "- Define configurações globais:\n",
    "  - Supressão de warnings não críticos\n",
    "  - Ajustes de exibição do pandas (linhas, colunas e largura)\n",
    "\n",
    "- Estabelece parâmetros do projeto:\n",
    "  - Caminhos para datasets e artefatos\n",
    "  - Hiperparâmetros globais (ex.: `TOP_N`, `TOP_K`, `RANDOM_STATE`)\n",
    "\n",
    "- Implementa função `read_csv_flex`:\n",
    "  - Busca arquivos `.csv` em múltiplos diretórios possíveis\n",
    "  - Testa diferentes separadores (`;`, `,`, autodetecção)\n",
    "  - Retorna `DataFrame` válido ou lança erro com histórico de tentativas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Imports principais =====\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== Módulos do scikit-learn =====\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit  # validação estratificada\n",
    "from sklearn.compose import ColumnTransformer                               # pré-processamento por tipo de coluna\n",
    "from sklearn.pipeline import Pipeline                                       # pipeline unificado\n",
    "from sklearn.impute import SimpleImputer                                    # imputação de valores faltantes\n",
    "from sklearn.preprocessing import OneHotEncoder                             # codificação categórica\n",
    "from sklearn.ensemble import RandomForestClassifier                         # classificador de árvores\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             average_precision_score, precision_recall_curve, roc_curve)  # métricas de avaliação\n",
    "from sklearn.inspection import permutation_importance                       # interpretabilidade\n",
    "from joblib import dump, load                                               # persistência de modelos\n",
    "\n",
    "# ===== Configurações globais =====\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # suprime avisos não críticos\n",
    "pd.set_option(\"display.max_columns\", None)              # exibe todas as colunas\n",
    "pd.set_option(\"display.width\", 220)                     # define largura máxima de exibição\n",
    "pd.set_option(\"display.max_rows\", 200)                  # aumenta limite de linhas exibidas\n",
    "\n",
    "# ===== Parâmetros do projeto =====\n",
    "CAMINHO_DF_HIST = \"../../../database/dataset gerado/dataset_limpo.csv\"                 # dataset histórico (limpo)\n",
    "ARQ_MODELO      = Path(\"../../../database/dataset gerado/modelo_grupo_chilli_simplificado.joblib\")    # arquivo para salvar/carregar modelo\n",
    "ARQ_NOVAS       = \"../../../database/dataset gerado/sugestoes_expansao_para_supervisionado.csv\"  # sugestões do não supervisionado\n",
    "TOP_N           = 10                                                 # número de categorias no ranking final\n",
    "TOP_K           = 1                                                  # top-k localidades\n",
    "FORCAR_TREINO   = False                                              # se True, força re-treinamento\n",
    "LIMIAR          = None                                               # limiar de decisão (se não definido, será calibrado)\n",
    "RANDOM_STATE    = 42                                                 # semente aleatória para reprodutibilidade\n",
    "\n",
    "# ===== Função utilitária para leitura flexível de CSV =====\n",
    "def read_csv_flex(base_path_or_stem: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lê um arquivo CSV de forma flexível, testando múltiplos caminhos e separadores.\n",
    "    Retorna um DataFrame se encontrado, caso contrário levanta FileNotFoundError.\n",
    "    \"\"\"\n",
    "    # Constrói lista de candidatos (caminho direto, com extensão, em pastas comuns)\n",
    "    candidates = [\n",
    "        Path(base_path_or_stem),\n",
    "        Path(f\"{base_path_or_stem}.csv\"),\n",
    "        Path(\"data\") / f\"{base_path_or_stem}.csv\",\n",
    "        Path(\"datasets\") / f\"{base_path_or_stem}.csv\",\n",
    "    ]\n",
    "    # Acrescenta arquivos encontrados no diretório de forma recursiva\n",
    "    for p in glob.glob(f\"**/{Path(base_path_or_stem).stem}*.csv\", recursive=True):\n",
    "        candidates.append(Path(p))\n",
    "\n",
    "    tried = []  # registra tentativas de leitura\n",
    "    for path in candidates:\n",
    "        if not path.exists():\n",
    "            tried.append(str(path))\n",
    "            continue\n",
    "        # Testa diferentes separadores\n",
    "        for sep in [None, ';', ',']:\n",
    "            try:\n",
    "                df = pd.read_csv(path, sep=sep, engine=\"python\")\n",
    "                print(f\"✔ Arquivo carregado de: {path}\")\n",
    "                return df\n",
    "            except Exception:\n",
    "                tried.append(f\"{path}(sep={sep})\")\n",
    "    # Se nenhum arquivo foi lido, lança erro com histórico de tentativas\n",
    "    raise FileNotFoundError(\"CSV não encontrado. Tentativas: \" + \" | \".join(tried))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb4716",
   "metadata": {},
   "source": [
    "### Construção da base supervisionada (features + rótulo por REGIÃO × GRUPO)\n",
    "\n",
    "- **Finalidade:** consolidar, em uma linha por par `REGIÃO × GRUPO`, as variáveis explicativas e o rótulo binário de desempenho.\n",
    "- **Entradas principais:** `df_hist` com colunas de preço (bruto e líquido), desconto, identificador de loja, região da loja e grupo de produto.\n",
    "- **Regras de negócio:**\n",
    "  - O rótulo `Bom_Desempenho` marca como 1 os **Top-K grupos por região** (maior receita líquida por par `REGIÃO × GRUPO`); demais pares recebem 0.\n",
    "  - As **features** incluem: receita total por região, número de lojas por região, receita por loja na região e **medianas por par `REGIÃO × GRUPO`** (preço de varejo e desconto).\n",
    "- **Artefatos auxiliares:**\n",
    "  - `catalogo` agrega metadados por grupo (ex.: `Grupo_Produto` e mediana de preço de varejo) para cruzar depois com as novas localidades.\n",
    "  - `agg_reg` e `grp_meds` ficam disponíveis para análises e enriquecimentos adicionais.\n",
    "- **Validações rápidas:**\n",
    "  - Conferir presença das colunas exigidas antes de agrupar.\n",
    "  - Conferir distribuição de `Bom_Desempenho` e a forma de `X_all`/`y_all`.\n",
    "  - Visualizar distribuição do alvo com um gráfico de barras simples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e preparar dados\n",
    "df = pd.read_csv(CAMINHO_DF_HIST)\n",
    "\n",
    "# Limpeza inicial dos dados\n",
    "df = df.drop(columns=[\n",
    "    \"ID_Cliente\",\"Dim_Cliente.Data_Nascimento\",\"Dim_Cliente.Regiao_Cliente\",\n",
    "    \"ID_Produto\",\"Dim_Lojas.Nome_Emp\",\"Dim_Lojas.Bairro_Emp\",\"Dim_Lojas.Cidade_Emp\",\n",
    "    \"Dim_Lojas.CANAL_VENDA\",\"Dim_Lojas.Tipo_PDV\",\"Dim_Lojas.Regiao\"\n",
    "], errors=\"ignore\")\n",
    "\n",
    "# Preparação dos dados para treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir variáveis preditoras (X) e alvo (y)\n",
    "X = df.drop('Dim_Produtos.GRUPO_CHILLI', axis=1)\n",
    "y = df['Dim_Produtos.GRUPO_CHILLI']\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Imports adicionais para pré-processamento\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Identificar colunas categóricas e numéricas\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Compatibilidade entre versões do sklearn para o OneHotEncoder\n",
    "if \"sparse_output\" in OneHotEncoder().get_params().keys():\n",
    "    oh = OneHotEncoder(\n",
    "        drop='first', \n",
    "        sparse_output=False,\n",
    "        handle_unknown='ignore'  # Ignora categorias desconhecidas\n",
    "    )  \n",
    "else:\n",
    "    oh = OneHotEncoder(\n",
    "        drop='first', \n",
    "        sparse=False,\n",
    "        handle_unknown='ignore'  # Ignora categorias desconhecidas\n",
    "    )\n",
    "\n",
    "# Criar preprocessador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', oh, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Criar pipeline com preprocessamento e modelo\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 1: Gráfico de Barras das Métricas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "metrics_df = pd.DataFrame(metrics).transpose()\n",
    "\n",
    "# Filter out the 'support' row and the macro/weighted averages\n",
    "metrics_df = metrics_df.drop(['support', 'accuracy'], errors='ignore')\n",
    "metrics_df = metrics_df.iloc[:-3]\n",
    "\n",
    "metrics_df[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Métricas de Classificação por Classe')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualização 2: Heatmap da Matriz de Confusão\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.xlabel('Valor Predito')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
